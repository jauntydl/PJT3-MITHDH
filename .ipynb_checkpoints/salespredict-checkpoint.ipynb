{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "datapath = 'resources/globalsales.csv'\n",
    "\n",
    "       \n",
    "def to_json(datapath, year = 2021, output = 'sales'):\n",
    "    \n",
    "    cats = [\"Furniture\", \"Office Supplies\", \"Technology\"]\n",
    "    subcats = [[\"Bookcases\", \"Furnishings\", \"Tables\", \"Chairs\"],[\"Appliances\", \"Binders\", \"Envelopes\", \"Fasteners\", \"Labels\", \"Paper\", \"Storage\", \"Supplies\", \"Art\"],[\"Accessories\", \"Machines\", \"Phones\", \"Copiers\"]]\n",
    "    markets = [\"Africa\", \"Asia Pacific\", \"Europe\", \"LATAM\", \"USCA\"]\n",
    "    regions = [[\"Central Africa\", \"Eastern Africa\", \"North Africa\", \"Southern Africa\", \"Western Africa\"],[\"Central Asia\", \"Eastern Asia\", \"Oceania\", \"Southeastern Asia\", \"Southern Asia\", \"Western Asia\"],[\"Eastern Europe\", \"Northern Europe\", \"Southern Europe\", \"Western Europe\"],[\"Caribbean\", \"Central America\", \"South America\"],[\"Canada\", \"Central US\", \"Eastern US\", \"Southern US\", \"Western US\"]]\n",
    "    \n",
    "    \n",
    "    data =[]\n",
    "    n1=0\n",
    "    alls = 'all'\n",
    "    for cat in cats:\n",
    "        d={}\n",
    "        d[\"cat\"] = cat\n",
    "        d[\"subcat\"] = alls\n",
    "        d[\"market\"] = alls\n",
    "        d[\"region\"] = alls                \n",
    "        d[\"y\"] ,d[\"y_fcst\"] ,d[\"MSE\"], d[\"MAPE\"] = return_forecast(datapath, year = year, output = output, cat = cat, subcat = alls, market = alls, region = alls)\n",
    "        data.append(d)\n",
    "\n",
    "        subcat_u = subcats[n1]\n",
    "        n1 = n1 + 1\n",
    "        for subcat in subcat_u:\n",
    "            d={}\n",
    "            d[\"cat\"] = cat\n",
    "            d[\"subcat\"] = subcat\n",
    "            d[\"market\"] = alls\n",
    "            d[\"region\"] = alls\n",
    "            d[\"y\"] ,d[\"y_fcst\"] ,d[\"MSE\"], d[\"MAPE\"] = return_forecast(datapath, year = year, output = output, cat = cat, subcat = subcat, market = alls, region = alls)\n",
    "            data.append(d)\n",
    "            n2 = 0\n",
    "            for market in markets:\n",
    "                d={}\n",
    "                d[\"cat\"] = cat\n",
    "                d[\"subcat\"] = subcat\n",
    "                d[\"market\"] = market\n",
    "                d[\"region\"] = alls\n",
    "                d[\"y\"] ,d[\"y_fcst\"] ,d[\"MSE\"], d[\"MAPE\"] = return_forecast(datapath, year = year, output = output, cat = cat, subcat = subcat, market = market, region = alls)\n",
    "                data.append(d)\n",
    "                \n",
    "    return data\n",
    "\n",
    "      \n",
    "def to_json_test(datapath, year = 2021, output = 'sales'):\n",
    "    \n",
    "    cats = [\"Furniture\", \"Office Supplies\", \"Technology\"]\n",
    "    subcats = [[\"Bookcases\", \"Furnishings\", \"Tables\", \"Chairs\"],[\"Appliances\", \"Binders\", \"Envelopes\", \"Fasteners\", \"Labels\", \"Paper\", \"Storage\", \"Supplies\", \"Art\"],[\"Accessories\", \"Machines\", \"Phones\", \"Copiers\"]]\n",
    "    markets = [\"Africa\", \"Asia Pacific\", \"Europe\", \"LATAM\", \"USCA\"]\n",
    "    regions = [[\"Central Africa\", \"Eastern Africa\", \"North Africa\", \"Southern Africa\", \"Western Africa\"],[\"Central Asia\", \"Eastern Asia\", \"Oceania\", \"Southeastern Asia\", \"Southern Asia\", \"Western Asia\"],[\"Eastern Europe\", \"Northern Europe\", \"Southern Europe\", \"Western Europe\"],[\"Caribbean\", \"Central America\", \"South America\"],[\"Canada\", \"Central US\", \"Eastern US\", \"Southern US\", \"Western US\"]]\n",
    "    \n",
    "    \n",
    "    data =[]\n",
    "    n1=0\n",
    "    alls = 'all'\n",
    "    \n",
    "    for cat in cats:\n",
    "        d={}\n",
    "        d[\"cat\"] = cat\n",
    "        d[\"subcat\"] = alls\n",
    "        d[\"market\"] = alls\n",
    "        d[\"region\"] = alls                \n",
    "        d[\"y\"] ,d[\"y_fcst\"] ,d[\"MSE\"], d[\"MAPE\"] = return_forecast(datapath, year = year, output = output, cat = cat, subcat = alls, market = alls, region = alls)\n",
    "        data.append(d)\n",
    "\n",
    "        subcat_u = subcats[n1]\n",
    "        n1 = n1 + 1\n",
    "        for subcat in subcat_u:\n",
    "            d={}\n",
    "            d[\"cat\"] = cat\n",
    "            d[\"subcat\"] = subcat\n",
    "            d[\"market\"] = alls\n",
    "            d[\"region\"] = alls\n",
    "            d[\"y\"] ,d[\"y_fcst\"] ,d[\"MSE\"], d[\"MAPE\"] = return_forecast(datapath, year = year, output = output, cat = cat, subcat = subcat, market = alls, region = alls)\n",
    "            data.append(d)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def filterdata(df1,output='sales', cat = \"all\", subcat = \"all\", market = \"all\", region = \"all\" ):\n",
    "    \n",
    "    if cat != \"all\":\n",
    "        df2 = df1[df1['cat']==cat]\n",
    "    else:\n",
    "        df2 = df1\n",
    "    if subcat != \"all\":\n",
    "        df3 = df2[df2['subcat']==subcat]\n",
    "    else:\n",
    "        df3 = df2\n",
    "    if market != \"all\":\n",
    "        df4 = df3[df3['market']==market]\n",
    "    else:\n",
    "        df4 = df3\n",
    "    if region != \"all\":\n",
    "        df5 = df4[df4['region']==region]\n",
    "    else:\n",
    "        df5 = df4\n",
    "                \n",
    "    df_filtered = df5.groupby(['date'], as_index = False)[\"{}\".format(output)].sum()\n",
    "    df_filtered = df_filtered.set_index('date').sort_values(by = 'date')\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def to_integer(dt_time):\n",
    "    return (dt_time.year-2016)*12 + dt_time.month\n",
    "\n",
    "def clean_data(datapath, output='sales', cat = \"all\", subcat = \"all\", market = \"all\", region = \"all\"):\n",
    "    df = pd.read_csv(datapath,encoding = \"ISO-8859-1\")\n",
    "    df.drop(df.columns[[0,1,2,3,5,6,7,8,9,10,11,12,13,16,17,25]], axis=1, inplace=True)\n",
    "    df.columns =['date',\"region\",\"market\",\"subcat\",\"cat\",\"sales\",\"quantity\",\"discount\",\"profit\",\"shippingcost\"]\n",
    "    df['date'] = df['date'].apply(lambda x: pd.to_datetime(str(x), format='%Y-%m-%d'))\n",
    "    df['date'] = df['date'].apply(lambda dt: dt.replace(day=1))\n",
    "    df_main = df.groupby(['date','region','market','subcat','cat'], as_index = False)['sales','profit','shippingcost'].sum()\n",
    "    result_df = filterdata(df_main, output=output, cat =cat, subcat =subcat, market =market, region =region)\n",
    "    return result_df\n",
    "\n",
    "def forecast_period(year):\n",
    "    fcst_date = []\n",
    "    for year in np.arange(2020,year+1):\n",
    "        for month in np.arange(1,13):\n",
    "            fcst_date.append(dt.datetime(year,month,1))\n",
    "    return fcst_date\n",
    "\n",
    "def return_forecast(datapath, year = 2021, output='sales', cat = \"all\", subcat = \"all\", market = \"all\", region = \"all\"):\n",
    "\n",
    "    result_df = clean_data(datapath, output=output, cat =cat, subcat =subcat, market =market, region =region)\n",
    "\n",
    "    sum_2017 = result_df[result_df.index.year == 2017] .sum()\n",
    "    sum_2018 = result_df[result_df.index.year == 2018] .sum()\n",
    "    sum_2019 = result_df[result_df.index.year == 2019] .sum()\n",
    "\n",
    "    growth_2018 =  sum_2018 / sum_2017\n",
    "    growth_2019 =  sum_2018 / sum_2017\n",
    "\n",
    "    Avg_growth = (growth_2018 + growth_2019)/2\n",
    "\n",
    "    X_forecast = forecast_period(year)\n",
    "\n",
    "    for row in X_forecast:\n",
    "        result_df.loc[row] = result_df.iloc[-12] * Avg_growth\n",
    "\n",
    "    df_diff = result_df.copy()\n",
    "\n",
    "    df_diff['prev'] = df_diff[output].shift(1)\n",
    "    df_diff['date'] = df_diff.index\n",
    "    df_diff['diff'] = (df_diff[output] - df_diff['prev'])\n",
    "\n",
    "    #create dataframe for transformation from time series to supervised\n",
    "    df_supervised = df_diff.drop(['prev'],axis=1)\n",
    "    #adding lags\n",
    "    for inc in range(1,13):\n",
    "        field_name = 'lag_' + str(inc)\n",
    "        df_supervised[field_name] = df_supervised['diff'].shift(inc)\n",
    "\n",
    "    #drop null values\n",
    "    df_supervised = df_supervised.dropna().reset_index(drop=True)\n",
    "\n",
    "    #import MinMaxScaler and create a new dataframe for LSTM model\n",
    "    df_model = df_supervised.drop([output,'date'],axis=1)\n",
    "\n",
    "    #split train and test set\n",
    "    train_set, test_set = df_model[0:-(len(X_forecast)+12)].values, df_model[-(len(X_forecast)+12):].values\n",
    "\n",
    "    #apply Min Max Scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train_set)\n",
    "\n",
    "    # reshape training set\n",
    "    train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])\n",
    "    train_set_scaled = scaler.transform(train_set)\n",
    "\n",
    "    # reshape test set\n",
    "    test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])\n",
    "    test_set_scaled = scaler.transform(test_set)\n",
    "\n",
    "    X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mape'])\n",
    "    model.fit(X_train, y_train, nb_epoch=100, batch_size=1, verbose=0, shuffle=False)\n",
    "    accuracy = model.evaluate(X_test, y_test, batch_size = 1)\n",
    "\n",
    "    y_pred = model.predict(X_test,batch_size=1)\n",
    "    #for multistep prediction, you need to replace X_test values with the predictions coming from t-1\n",
    "\n",
    "    #reshape y_pred\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n",
    "\n",
    "    #rebuild test set for inverse transform\n",
    "    pred_test_set = []\n",
    "    for index in range(0,len(y_pred)):\n",
    "        pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
    "\n",
    "    pred_test_set = np.array(pred_test_set)\n",
    "    pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n",
    "    pred_test_set_inverted = scaler.inverse_transform(pred_test_set)\n",
    "\n",
    "    #create dataframe that shows the predicted sales\n",
    "    result_list = []\n",
    "    dates = list(result_df[-(len(X_forecast)+13):].index)\n",
    "    act_value = list(result_df[-(len(X_forecast)+13):][output])\n",
    "\n",
    "    for index in range(0,len(pred_test_set_inverted)):\n",
    "        result_dict = {}\n",
    "        result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_value[index])\n",
    "        result_dict['date'] = dates[index+1]\n",
    "        result_list.append(result_dict)\n",
    "    df_result = pd.DataFrame(result_list)\n",
    "    #for multistep prediction, replace act_sales with the predicted sales\n",
    "\n",
    "    #merge with actual sales dataframe\n",
    "    df_sales_pred = pd.merge(result_df,df_result,on='date',how='left')\n",
    "    df_sales_pred.iloc[-(len(X_forecast)):,1] = np.nan\n",
    "\n",
    "    return list(df_sales_pred[output]), list(df_sales_pred['pred_value']), accuracy[0], accuracy[1]\n",
    "\n",
    "def return_model(datapath, year = 2021, output='sales', cat = \"all\", subcat = \"all\", market = \"all\", region = \"all\"):\n",
    "\n",
    "    result_df = clean_data(datapath, output=output, cat =cat, subcat =subcat, market =market, region =region)\n",
    "\n",
    "    df_diff = result_df.copy()\n",
    "\n",
    "    df_diff['prev'] = df_diff[output].shift(1)\n",
    "    df_diff['date'] = df_diff.index\n",
    "    df_diff['diff'] = (df_diff[output] - df_diff['prev'])\n",
    "\n",
    "    #create dataframe for transformation from time series to supervised\n",
    "    df_supervised = df_diff.drop(['prev'],axis=1)\n",
    "    #adding lags\n",
    "    for inc in range(1,13):\n",
    "        field_name = 'lag_' + str(inc)\n",
    "        df_supervised[field_name] = df_supervised['diff'].shift(inc)\n",
    "\n",
    "    #drop null values\n",
    "    df_supervised = df_supervised.dropna().reset_index(drop=True)\n",
    "\n",
    "    #import MinMaxScaler and create a new dataframe for LSTM model\n",
    "    df_model = df_supervised.drop([output,'date'],axis=1)\n",
    "\n",
    "    #split train and test set\n",
    "    train_set, test_set = df_model[0:-(12)].values, df_model[-(12):].values\n",
    "\n",
    "    #apply Min Max Scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train_set)\n",
    "\n",
    "    # reshape training set\n",
    "    train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])\n",
    "    train_set_scaled = scaler.transform(train_set)\n",
    "\n",
    "    # reshape test set\n",
    "    test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])\n",
    "    test_set_scaled = scaler.transform(test_set)\n",
    "\n",
    "    X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mape'])\n",
    "    model.fit(X_train, y_train, nb_epoch=100, batch_size=1, verbose=1, shuffle=False)\n",
    "    accuracy = model.evaluate(X_test, y_test, batch_size = 1)\n",
    "\n",
    "    y_pred = model.predict(X_test,batch_size=1)\n",
    "    #for multistep prediction, you need to replace X_test values with the predictions coming from t-1\n",
    "\n",
    "    #reshape y_pred\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n",
    "\n",
    "    #rebuild test set for inverse transform\n",
    "    pred_test_set = []\n",
    "    for index in range(0,len(y_pred)):\n",
    "        pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
    "\n",
    "    pred_test_set = np.array(pred_test_set)\n",
    "    pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n",
    "    pred_test_set_inverted = scaler.inverse_transform(pred_test_set)\n",
    "\n",
    "    #create dataframe that shows the predicted sales\n",
    "    result_list = []\n",
    "    dates = list(result_df[-(13):].index)\n",
    "    act_value = list(result_df[-(13):][output])\n",
    "\n",
    "    for index in range(0,len(pred_test_set_inverted)):\n",
    "        result_dict = {}\n",
    "        result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_value[index])\n",
    "        result_dict['date'] = dates[index+1]\n",
    "        result_list.append(result_dict)\n",
    "    df_result = pd.DataFrame(result_list)\n",
    "    #for multistep prediction, replace act_sales with the predicted sales\n",
    "\n",
    "    #merge with actual sales dataframe\n",
    "    df_sales_pred = pd.merge(result_df,df_result,on='date',how='left')\n",
    "\n",
    "    return list(df_sales_pred[output]), list(df_sales_pred['pred_value']), accuracy[0], accuracy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "36/36 [==============================] - 0s 6ms/step\n",
      "36/36 [==============================] - 0s 6ms/step\n",
      "36/36 [==============================] - 0s 7ms/step\n",
      "36/36 [==============================] - 0s 8ms/step\n",
      "36/36 [==============================] - 0s 6ms/step\n",
      "36/36 [==============================] - 0s 8ms/step\n",
      "36/36 [==============================] - 0s 7ms/step\n",
      "36/36 [==============================] - 0s 7ms/step\n",
      "36/36 [==============================] - 0s 8ms/step\n",
      "36/36 [==============================] - 0s 9ms/step\n",
      "36/36 [==============================] - 0s 8ms/step\n",
      "36/36 [==============================] - 0s 8ms/step\n",
      "36/36 [==============================] - 0s 9ms/step\n",
      "36/36 [==============================] - 0s 9ms/step\n",
      "36/36 [==============================] - 0s 9ms/step\n",
      "36/36 [==============================] - 0s 10ms/step\n",
      "36/36 [==============================] - 0s 10ms/step\n",
      "36/36 [==============================] - 0s 10ms/step\n",
      "36/36 [==============================] - 0s 10ms/step\n",
      "36/36 [==============================] - 0s 10ms/step\n",
      "36/36 [==============================] - 0s 11ms/step\n",
      "36/36 [==============================] - 0s 12ms/step\n",
      "36/36 [==============================] - 0s 12ms/step\n",
      "36/36 [==============================] - 0s 12ms/step\n",
      "36/36 [==============================] - 1s 21ms/step\n",
      "36/36 [==============================] - 0s 13ms/step\n",
      "36/36 [==============================] - 1s 16ms/step\n",
      "36/36 [==============================] - 0s 14ms/step\n",
      "36/36 [==============================] - 1s 15ms/step\n",
      "36/36 [==============================] - 1s 22ms/step\n",
      "36/36 [==============================] - 1s 19ms/step\n",
      "36/36 [==============================] - 1s 20ms/step\n",
      "36/36 [==============================] - 1s 26ms/step\n",
      "36/36 [==============================] - 1s 16ms/step\n",
      "36/36 [==============================] - 1s 18ms/step\n",
      "36/36 [==============================] - 1s 23ms/step\n",
      "36/36 [==============================] - 1s 23ms/step\n",
      "36/36 [==============================] - 1s 21ms/step\n",
      "36/36 [==============================] - 1s 19ms/step\n",
      "36/36 [==============================] - 1s 24ms/step\n",
      "36/36 [==============================] - 1s 20ms/step\n",
      "36/36 [==============================] - 1s 30ms/step\n",
      "36/36 [==============================] - 1s 26ms/step\n",
      "36/36 [==============================] - 1s 24ms/step\n",
      "36/36 [==============================] - 1s 21ms/step\n",
      "36/36 [==============================] - 1s 23ms/step\n",
      "36/36 [==============================] - 1s 21ms/step\n",
      "36/36 [==============================] - 1s 29ms/step\n",
      "36/36 [==============================] - 1s 33ms/step\n",
      "36/36 [==============================] - 1s 21ms/step\n",
      "36/36 [==============================] - 1s 25ms/step\n",
      "36/36 [==============================] - 1s 25ms/step\n",
      "36/36 [==============================] - 1s 24ms/step\n",
      "36/36 [==============================] - 1s 29ms/step\n",
      "36/36 [==============================] - 1s 33ms/step\n",
      "36/36 [==============================] - 1s 30ms/step\n",
      "36/36 [==============================] - 1s 28ms/step\n",
      "36/36 [==============================] - 1s 41ms/step\n",
      "36/36 [==============================] - 1s 28ms/step\n",
      "36/36 [==============================] - 1s 33ms/step\n",
      "36/36 [==============================] - 1s 30ms/step\n",
      "36/36 [==============================] - 1s 28ms/step\n",
      "36/36 [==============================] - 1s 30ms/step\n",
      "36/36 [==============================] - 1s 40ms/step\n",
      "36/36 [==============================] - 1s 35ms/step\n",
      "36/36 [==============================] - 1s 36ms/step\n",
      "36/36 [==============================] - 1s 36ms/step\n",
      "36/36 [==============================] - 1s 36ms/step\n",
      "36/36 [==============================] - 1s 37ms/step\n",
      "36/36 [==============================] - 1s 39ms/step\n",
      "36/36 [==============================] - 1s 35ms/step\n",
      "36/36 [==============================] - 1s 38ms/step\n",
      "36/36 [==============================] - 1s 39ms/step\n",
      "36/36 [==============================] - 1s 36ms/step\n",
      "36/36 [==============================] - 1s 36ms/step\n",
      "36/36 [==============================] - 1s 36ms/step\n",
      "36/36 [==============================] - 1s 39ms/step\n",
      "36/36 [==============================] - 2s 44ms/step\n",
      "36/36 [==============================] - 1s 34ms/step\n",
      "36/36 [==============================] - 1s 41ms/step\n",
      "36/36 [==============================] - 1s 34ms/step\n",
      "36/36 [==============================] - 1s 36ms/step\n",
      "36/36 [==============================] - 1s 35ms/step\n",
      "36/36 [==============================] - 1s 37ms/step\n",
      "36/36 [==============================] - 1s 37ms/step\n",
      "36/36 [==============================] - 1s 39ms/step\n",
      "36/36 [==============================] - 2s 45ms/step\n",
      "36/36 [==============================] - 1s 38ms/step\n",
      "36/36 [==============================] - 1s 39ms/step\n",
      "36/36 [==============================] - 1s 39ms/step\n",
      "36/36 [==============================] - 2s 43ms/step\n",
      "36/36 [==============================] - 2s 50ms/step\n",
      "36/36 [==============================] - 2s 43ms/step\n",
      "36/36 [==============================] - 2s 46ms/step\n",
      "36/36 [==============================] - 1s 41ms/step\n",
      "36/36 [==============================] - 2s 55ms/step\n",
      "36/36 [==============================] - 2s 42ms/step\n",
      "36/36 [==============================] - 2s 45ms/step\n",
      "36/36 [==============================] - 2s 49ms/step\n",
      "36/36 [==============================] - 2s 56ms/step\n",
      "36/36 [==============================] - 2s 44ms/step\n",
      "36/36 [==============================] - 2s 46ms/step\n",
      "36/36 [==============================] - 2s 59ms/step\n",
      "36/36 [==============================] - 2s 47ms/step\n",
      "36/36 [==============================] - 2s 48ms/step\n",
      "36/36 [==============================] - 2s 48ms/step\n",
      "36/36 [==============================] - 2s 48ms/step\n",
      "36/36 [==============================] - 2s 56ms/step\n",
      "36/36 [==============================] - 2s 62ms/step\n",
      "36/36 [==============================] - 2s 66ms/step\n",
      "36/36 [==============================] - 2s 57ms/step\n",
      "36/36 [==============================] - 3s 74ms/step\n",
      "36/36 [==============================] - 2s 63ms/step\n",
      "36/36 [==============================] - 2s 69ms/step\n",
      "36/36 [==============================] - 2s 55ms/step\n",
      "36/36 [==============================] - 2s 57ms/step\n",
      "36/36 [==============================] - 3s 78ms/step\n",
      "36/36 [==============================] - 2s 56ms/step\n",
      "36/36 [==============================] - 2s 58ms/step\n",
      "36/36 [==============================] - 3s 73ms/step\n",
      "36/36 [==============================] - 2s 58ms/step\n",
      "36/36 [==============================] - 2s 65ms/step\n",
      "36/36 [==============================] - 2s 65ms/step\n",
      "36/36 [==============================] - 2s 68ms/step\n",
      "36/36 [==============================] - 2s 61ms/step\n",
      "36/36 [==============================] - 3s 72ms/step\n",
      "36/36 [==============================] - 2s 62ms/step\n",
      "36/36 [==============================] - 3s 71ms/step\n",
      "36/36 [==============================] - 3s 73ms/step\n",
      "36/36 [==============================] - 3s 87ms/step\n",
      "36/36 [==============================] - 3s 88ms/step\n",
      "36/36 [==============================] - 3s 94ms/step\n",
      "36/36 [==============================] - 3s 86ms/step\n",
      "36/36 [==============================] - 3s 74ms/step\n",
      "36/36 [==============================] - 3s 70ms/step\n",
      "36/36 [==============================] - 3s 73ms/step\n",
      "36/36 [==============================] - 3s 85ms/step\n",
      "36/36 [==============================] - 3s 84ms/step\n",
      "36/36 [==============================] - 3s 81ms/step\n",
      "36/36 [==============================] - 3s 73ms/step\n",
      "36/36 [==============================] - 4s 98ms/step\n",
      "36/36 [==============================] - 3s 76ms/step\n",
      "36/36 [==============================] - 4s 100ms/step\n",
      "36/36 [==============================] - 3s 91ms/step\n",
      "36/36 [==============================] - 3s 78ms/step\n",
      "36/36 [==============================] - 4s 98ms/step\n",
      "36/36 [==============================] - 3s 79ms/step\n",
      "36/36 [==============================] - 3s 90ms/step\n",
      "36/36 [==============================] - 3s 92ms/step\n",
      "36/36 [==============================] - 3s 96ms/step\n",
      "36/36 [==============================] - 3s 90ms/step\n",
      "36/36 [==============================] - 3s 95ms/step\n",
      "36/36 [==============================] - 3s 90ms/step\n",
      "36/36 [==============================] - 4s 97ms/step\n",
      "36/36 [==============================] - 4s 104ms/step\n",
      "36/36 [==============================] - 4s 106ms/step\n",
      "36/36 [==============================] - 4s 99ms/step\n",
      "36/36 [==============================] - 3s 91ms/step\n",
      "36/36 [==============================] - 3s 91ms/step\n",
      "36/36 [==============================] - 4s 115ms/step\n",
      "36/36 [==============================] - 3s 92ms/step\n",
      "36/36 [==============================] - 4s 104ms/step\n",
      "36/36 [==============================] - 4s 98ms/step\n",
      "36/36 [==============================] - 4s 109ms/step\n",
      "36/36 [==============================] - 4s 118ms/step\n",
      "36/36 [==============================] - 4s 102ms/step\n",
      "36/36 [==============================] - 4s 112ms/step\n",
      "36/36 [==============================] - 4s 111ms/step\n",
      "36/36 [==============================] - 4s 107ms/step\n",
      "36/36 [==============================] - 4s 110ms/step\n",
      "36/36 [==============================] - 4s 110ms/step\n",
      "36/36 [==============================] - 5s 128ms/step\n",
      "36/36 [==============================] - 4s 125ms/step\n",
      "36/36 [==============================] - 5s 127ms/step\n",
      "36/36 [==============================] - 4s 116ms/step\n",
      "36/36 [==============================] - 4s 122ms/step\n",
      "36/36 [==============================] - 4s 120ms/step\n",
      "36/36 [==============================] - 4s 115ms/step\n",
      "36/36 [==============================] - ETA:  - 4s 113ms/step\n",
      "36/36 [==============================] - 4s 116ms/step\n",
      "36/36 [==============================] - 5s 128ms/step\n",
      "36/36 [==============================] - 5s 128ms/step\n",
      "36/36 [==============================] - 5s 129ms/step\n",
      "36/36 [==============================] - 5s 128ms/step\n",
      "36/36 [==============================] - 4s 115ms/step\n",
      "36/36 [==============================] - 5s 134ms/step\n",
      "36/36 [==============================] - 4s 122ms/step\n",
      "36/36 [==============================] - 4s 125ms/step\n",
      "36/36 [==============================] - 5s 141ms/step\n",
      "36/36 [==============================] - 5s 139ms/step\n",
      "36/36 [==============================] - 4s 119ms/step\n",
      "36/36 [==============================] - 5s 142ms/step\n",
      "36/36 [==============================] - 4s 123ms/step\n",
      "36/36 [==============================] - 4s 123ms/step\n",
      "36/36 [==============================] - 5s 136ms/step\n",
      "36/36 [==============================] - 5s 135ms/step\n",
      "36/36 [==============================] - 5s 140ms/step\n",
      "36/36 [==============================] - 6s 159ms/step\n",
      "36/36 [==============================] - 5s 149ms/step\n",
      "36/36 [==============================] - 5s 149ms/step\n",
      "36/36 [==============================] - 6s 165ms/step\n",
      "36/36 [==============================] - 5s 142ms/step\n",
      "36/36 [==============================] - 5s 142ms/step\n",
      "36/36 [==============================] - 5s 138ms/step\n",
      "36/36 [==============================] - 5s 147ms/step\n",
      "36/36 [==============================] - 6s 165ms/step\n",
      "36/36 [==============================] - 5s 145ms/step\n",
      "36/36 [==============================] - 5s 139ms/step\n",
      "36/36 [==============================] - 6s 154ms/step\n",
      "36/36 [==============================] - 6s 157ms/step\n",
      "36/36 [==============================] - 5s 151ms/step\n",
      "36/36 [==============================] - 6s 160ms/step\n",
      "36/36 [==============================] - 6s 166ms/step\n",
      "36/36 [==============================] - 7s 182ms/step\n",
      "36/36 [==============================] - 6s 158ms/step\n",
      "36/36 [==============================] - 6s 174ms/step\n",
      "36/36 [==============================] - 6s 160ms/step\n",
      "36/36 [==============================] - 6s 161ms/step\n",
      "36/36 [==============================] - 6s 178ms/step\n",
      "36/36 [==============================] - 7s 187ms/step\n",
      "36/36 [==============================] - 6s 164ms/step\n",
      "36/36 [==============================] - 6s 171ms/step\n",
      "36/36 [==============================] - 6s 177ms/step\n",
      "36/36 [==============================] - 7s 188ms/step\n",
      "36/36 [==============================] - 6s 157ms/step\n",
      "36/36 [==============================] - 7s 186ms/step\n",
      "36/36 [==============================] - 6s 163ms/step\n",
      "36/36 [==============================] - 6s 167ms/step\n",
      "36/36 [==============================] - 7s 199ms/step\n",
      "36/36 [==============================] - 7s 187ms/step\n",
      "36/36 [==============================] - 7s 181ms/step\n",
      "36/36 [==============================] - 7s 187ms/step\n",
      "36/36 [==============================] - 6s 175ms/step\n",
      "36/36 [==============================] - 7s 181ms/step\n",
      "36/36 [==============================] - 6s 168ms/step\n",
      "36/36 [==============================] - 7s 203ms/step\n",
      "36/36 [==============================] - ETA:  - 6s 179ms/step\n",
      "36/36 [==============================] - 8s 227ms/step\n",
      "36/36 [==============================] - 7s 196ms/step\n",
      "36/36 [==============================] - 7s 184ms/step\n",
      "36/36 [==============================] - 7s 183ms/step\n"
     ]
    }
   ],
   "source": [
    "json_forecasts = to_json(datapath)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forecastresults', 'w') as fout:\n",
    "    json.dump(json_forecasts, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
